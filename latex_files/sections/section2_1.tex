~\\
\section{Numerical methods}
Computational modeling of the natural world involves pervasive material and
geometric complexities that are hard to understand, incorporate, and analyze.
%
The partial differential equations (PDEs) governing many of these systems are
subject to boundary and interface conditions, and all numerical methods share
the fundamental challenge of how to enforce these conditions in a stable manner.
Additionally, applications involving elliptic PDEs or implicit time-stepping require efficient solution strategies for linear systems of equations. 


Most applications in the natural sciences are characterized by multiscale features in both space and time which can lead to huge linear systems of equations after discretization. Our work is motivated by large-scale ($\sim$hundreds of kilometers) earthquake cycle simulations where frictional faults are idealized as geometrically complex interfaces within a 3D material volume and are characterized by much smaller-scale features ($\sim$microns) \cite{Erickson2014, Kozdon2012InteractionOW}. In contrast to the single-event simulations, e.g. \cite{Roten}, where the computational work at each time step is a single matrix-vector product, earthquake cycle simulations must integrate with adaptive time-steps through the slow periods between earthquakes, and are tasked with a much more costly linear solve.  For example, even with upscaled parameters so that larger grid spacing can be
used, the 2D simulations in ~\cite{Erickson2014} generated matrices of size
$\sim$10$^6$, and improved resolution and 3D domains would increase the system
size to $\sim$10$^9$ or greater.
% %
Because iterative schemes are most often implemented for the linear solve (since direct methods require a matrix factorization that is often too large to store in memory), it is no surprise that the sparse matrix-vector product (SpMV) arises as the main computational workhorse. The matrix sparsity and condition number depend on several physical and numerical factors including the material heterogeneity of the Earth’s material properties, order of accuracy, the coordinate transformation (for irregular grids), and the mesh size.  For large-scale problems, matrix-free (on-the-fly) techniques for the SpMV are fundamental when the matrix cannot be stored explicitly.

In this work, we use summation-by-parts (SBP) finite difference
methods ~\cite{KS74, Strand94, MN04, SVARD201417}, which are distinct from traditional finite difference
methods in their use of specific one-sided approximations at domain boundaries that enable the highly valuable proof of stability, a necessity for numerical convergence. Weak enforcement of boundary conditions has additional superior properties over traditional methods, for example, the simultaneous-approximation-term (SAT) technique, which relaxes continuity requirements (of the grid and the solution) across physical or geometrical interfaces, with low communication overhead for efficient parallel algorithms \cite{Fernandez2014}.

For these reasons SBP-SAT methods are widely used in many areas of scientific computing, from the flow over airplane wings to biological membranes to earthquakes and tsunamigenesis ~\cite{Ying2007, NordstromEriksson2010, Swim2011, petersson_stable, Lotto2015, EricksonDay2016}; these studies, however, have not been developed for linear solves or were limited to small-scale simulations. 

% For these reasons SBP-SAT methods are widely used in many areas of scientific computing, from the flow over airplane wings to biological membranes to earthquakes and tsunamigenesis ~\cite{Ying2007, NordstromEriksson2010, Swim2011, petersson_sjögreen_2012, Lotto2015, EricksonDay2016}; these studies, however, have not been developed for linear solves or were limited to small-scale simulations. 

With this work, we contribute a novel iterative scheme for linear systems based on SBP-SAT discretizations where nontrivial computations arise due to boundary treatment. These methods are integrated into our existing, public software for simulations of earthquake sequences. Specifically, we make the following contributions: 
\begin{itemize}
\item Since preconditioning of iterative methods is a hugely consequential step towards improving convergence rates, we develop a custom geometric multigrid preconditioned conjugate gradient (MGCG) algorithm which shows a near-constant number of iterations with increasing system size. The required iterations (and time-to-solution) are much lower compared to several off-the-shelf preconditioners offered by the PETSc library \cite{petsc-web-page}, a state-of-the-art library for scientific computing.
\item We develop custom, matrix-free GPU kernels (specifically for SBP-SAT methods) for computations in the volume and boundaries, which show improved performance as compared to the native, matrix-explicit implementation while requiring only a fraction of memory. 
\item GPU-acceleration of our resulting matrix-free, preconditioned iterative scheme shows superior performance compared to state-of-the-art methods offered by NVIDIA.
\end{itemize} 
%
Furthermore, the ubiquity of SBP-SAT methods in modern scientific computing applications means our work has the propensity to advance scientific studies currently limited to small-scale problems.

% The paper is organized as follows: First, we present related (albeit limited) work on preconditioning and GPU acceleration of iterative schemes for SBP-SAT methods. Next, we provide a detailed description of our model problem, followed by the corresponding SBP-SAT discretization which generates the linear system we focus on in this work. We include details of our code development in the Julia programming language and its HPC capabilities and verify our solutions through rigorous spatial convergence tests to ascertain correctness. We next discuss a two-pronged approach for accelerating time-to-solution, with developed methods customized for SBP-SAT methods. The first is through a preconditioning approach, which can be thought of as a mathematical means for reducing the number of overall iterations required for the iterative scheme to converge.  Second, individual iterations can be accelerated by GPU parallelism and the development of matrix-free operations. Preconditioning and parallel performance are compared against options from several state-of-the-art libraries (PETSc and NVIDIA AmgX). We conclude with a summary of our results and proposed future work.




% \section{Related Work}\label{sec: related}
% Conjugate gradient (CG) is a standard iterative method for solving linear systems involving symmetric positive-definite (SPD) matrices. But the performance of CG often relies fundamentally on specialized preconditioning techniques specific to the application, e.g.  ~\cite{Aagaard2013,osusky2013parallel,yang2002boomeramg,10.1007/3-540-47789-6_66}. To our knowledge, no systematic studies of preconditioning performance for SBP-SAT methods have been done until this study.  Multigrid (MG) is a technique for both solving and preconditioning linear systems using a hierarchy of successively coarser grids. Three key ingredients define multigrid methods, namely, interpolation operators (prolongation and restriction), smoothers, and (if used) a direct solve on a coarse grid. MG has inherent high-parallelism, smooths low-frequency error components, and has proven to be a highly successful preconditioner for improving convergence rates in a wide range of application problems ~\cite{Tatebe}. In \cite{Ruggiu2018}, MG methods were explored for SBP-SAT methods, and the development of SBP-preserving interpolation operators showed improved performance by modifying standard interpolation operators near boundaries. However, these studies only explored MG as a solver, and not its effectiveness as a preconditioner. In addition, they applied Galerkin coarsening to produce the coarse grid operators rather than through a rediscretization of the original PDE. Because part of the focus of our work is the development of matrix-free methods, defining the coarse grid operators in this fashion would require writing an entirely different kernel for every grid level, as well as more memory for data storage \cite{brandt2006guide}. Therefore, to fully utilize the efficiency of our matrix-free methods, as well as to reduce complexity in and the number of kernels needed, our focus is on rediscretization approaches when using MG as a preconditioner for CG (denoted MGCG). 



% The CG iteration itself involves three components: the sparse matrix data structure (if matrix-explicit methods are used), the reduction operations to compute inner products, and the matrix-vector multiply. For such matrix-explicit methods, loading the matrix from device memory often dominates SpMV performance. Even though GPUs are bandwidth rich (an order of magnitude or higher than CPUs), making them ideally suited for SpMV \cite{Choi2010}, the SpMV constitutes the majority of the computational load. Specifically, performance can be limited by low computational intensity, irregular memory access, and sparsity \cite{spmvbook}, and though not the focus of this work, much effort has been devoted to sparse matrix data structures such as CSR (our baseline comparison), ELL, COO, and BELLPACK (GPU only) \cite{Bell2009, Baskaran2009, Choi2010, Vazquez2011, yan2014yaspmv, benatia2018bestsf,alahmadi2020performance}. 





% To our knowledge, the only previous work on SBP-SAT methods on the GPU considered a matrix-explicit SpMV \cite{10.1145/3398329.3398336}, or used stencil computations in seismic wave propagations but did not solve linear systems \cite{pankajakshan2019porting}. 
% Here we develop a matrix-free implementation of the SpMV and corresponding MGCG method to solve our model problem. Matrix-free methods include the additional benefits of increased arithmetic intensity and reduced memory footprint and do not require matrix assembly (which can be cumbersome for complex applications), all of which can improve performance on modern, bandwidth-limited processors \cite{Brown2010, Muller2013, 10.5555/3108096.3108097, Fabien2017}.